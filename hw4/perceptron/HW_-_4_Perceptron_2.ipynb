{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea48a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076da5ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Биологический нейрон</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2255b724",
   "metadata": {},
   "source": [
    "**Нейрон** — электрически возбудимая клетка, которая предназначена для приёма извне, обработки, хранения, передачи и вывода вовне информации с помощью электрических и химических сигналов.  \n",
    "  \n",
    "Типичный нейрон состоит из тела клетки, дендритов и одного аксона:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa916480",
   "metadata": {},
   "source": [
    "![neuron](images/neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30244433",
   "metadata": {},
   "source": [
    "Простыми словами можно описать принцип действия нейрона следующим образом:\n",
    "- через дендриты в нейрон поступают сигналы (раздражители)\n",
    "- Если комбинация сигналов превышает пороговый уровень - нейрон \"выстреливает\", т.е. передаёт сигнал дальше через аксон."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7ce203",
   "metadata": {},
   "source": [
    "Нейроны могут соединяться один с другим, формируя нервные сети."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5200e275",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Функции Активации (Activation Functions)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d41f55f",
   "metadata": {},
   "source": [
    "Простейшим механизмом активации является **Step activation**, когда перспептрон передаёт на выход значение только в том случае, если сумма взвешенных входящих сигналов больше заданного порога:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff07a8e1",
   "metadata": {},
   "source": [
    "![step](images/step_activation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b588aa",
   "metadata": {},
   "source": [
    "При всей своей простоте, данная функция активации обладает критическим недостатком: она недифференцируемая.  Как результат, она не позволяет осуществлять процесс обучения персептрона.  \n",
    "  \n",
    "Для того, чтобы исправить это, было разработано множество других функций активаций, таких как:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf346ed",
   "metadata": {},
   "source": [
    "![neuron](images/activation_functions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d1d1b0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 1 (2 балла)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be49dd4",
   "metadata": {},
   "source": [
    "Напишите класс **ActivationFunction** и его подкласс **Sigmoid**, у которого будет функция `forward`, которая:\n",
    "- будет принимать на вход число и будет сохранять его внутри объекта\n",
    "- будет возвращать результат в соответствии с фукцией $\\sigma(x) = \\frac{1}{1 + e^{-x}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a68d43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991837717806398"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math \n",
    "\n",
    "\n",
    "class ActivationFunction:\n",
    "    ...\n",
    "\n",
    "\n",
    "class Sigmoid(ActivationFunction):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sigma: float\n",
    "        \n",
    "    def forward(self, value: float) -> float:\n",
    "        self.sigma = 1 / (1 + math.exp(-value))\n",
    "        return self.sigma\n",
    "    \n",
    "        \n",
    "a = Sigmoid()\n",
    "a.forward(7.11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c54ea44",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78315b25",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53618f50",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Персептрон</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266324a8",
   "metadata": {},
   "source": [
    "**Персептрон** -  математическая модель биологического нейрона, является базовым элементом нейронных сетей:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f671b",
   "metadata": {},
   "source": [
    "![neuron](images/perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc65e4",
   "metadata": {},
   "source": [
    "**Персептрон** состоит из следующих ключевых элементов:\n",
    "- `вход` - отвечает за получение входных значений. Является аналогом дендрита биологического нейрона\n",
    "- `веса` - механизм \"важности\" входных значений. По аналогии с нейроном - это \"толщина\" дендрита\n",
    "- `функция активации` - обрабатывает сумму взвешенных входных сигналов и передаёт результат на выход\n",
    "- `выход` - отвечает за передачу итогового результата. Аналогичен аксону\n",
    "  \n",
    "Практически всегда к входным сигналам также добавляется \"bias\", который всегда = 1.  \n",
    "Это позволяет не привязывать выход персептрона к 0 в случае, если все входные сигналы также равны 0 (как в механизме регрессии)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057194ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 2 (4 балла)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42423ee",
   "metadata": {},
   "source": [
    "напишите класс **Layer**, у когорого будут следующие входные параметры:\n",
    "- **n_inputs** - количество входящих значений\n",
    "- **n_outputs** - количество исходящих значений (в нашем случае = 1)\n",
    "- **activation** - объект из семейства **ActivationFunction** (в нашем случае - **Sigmoid**)\n",
    "  \n",
    "При своём создании объект класса **Layer** должен также создавать атрибут `weights_`, в ктором будут рандомально инициализированны веса для входящих значений, а также для `bias`\n",
    "\n",
    "Класс **Layer** должен иметь функцию `forward`, принимающую на вход массив *numpy*, и возвращающую результат функции активации (тоже в виде массива).  \n",
    "Также эта функция должна сохранять полученные на вход значения внутри экземпляра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04ec3681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "\n",
    "class Layer:\n",
    "\n",
    "    def __init__(self, n_inputs: int, activation: Sigmoid, learning_rate: float, epohs: int, n_outputs: int = 1):\n",
    "        self.n_inputs = n_inputs\n",
    "        self.n_outputs = n_outputs\n",
    "        self.activation = activation\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epohs = epohs\n",
    "        rng = default_rng()\n",
    "        self.weights_ = rng.random(n_inputs)\n",
    "        self.weights_[0] = 1\n",
    "        self.entries: np.ndarray\n",
    "    \n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        self.entries = X.copy()\n",
    "        return np.array([self.activation.forward(np.dot(self.entries, self.weights_.T))])\n",
    "    \n",
    "    def back(self, y_fact: np.ndarray):\n",
    "        \n",
    "        def fx_derivative(x: float):\n",
    "            return math.exp(-x) / (1 + math.exp(-x))**2\n",
    "        \n",
    "        def loss_derivative(y_fact: np.ndarray, y_prob: np.ndarray) -> float: \n",
    "            return y_fact/y_prob + (y_fact - 1)/(1 - y_prob)\n",
    "        \n",
    "        def f(X):\n",
    "            return \n",
    "        \n",
    "        y_prob = Layer.forward(self, X=self.entries)\n",
    "        loss = CrossEntropy().loss(y_fact=y_fact, y_prob=y_prob)\n",
    "            \n",
    "        for _ in range(self.epohs):\n",
    "            y_prob = Layer.forward(self, X=self.entries)\n",
    "            loss = CrossEntropy().loss(y_fact=y_fact, y_prob=y_prob)\n",
    "            sigm = Sigmoid().forward(np.dot(self.entries, self.weights_.T))\n",
    "        \n",
    "            for ind, i in enumerate(self.entries):\n",
    "                self.weights_[ind] += i * fx_derivative(x=sigm) * self.learning_rate * loss_derivative(y_fact, y_prob)\n",
    "            \n",
    "            print(loss)\n",
    "            print('y', y_prob)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84a33bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1451319093026629\n",
      "y [0.8649082]\n",
      "0.14019624134068678\n",
      "y [0.86918765]\n",
      "0.13544862137686856\n",
      "y [0.87332403]\n",
      "0.13088052586960097\n",
      "y [0.87732259]\n",
      "0.12648391025132366\n",
      "y [0.88118833]\n",
      "0.12225117560762071\n",
      "y [0.88492607]\n",
      "0.11817513814126777\n",
      "y [0.88854042]\n",
      "0.11424900115016617\n",
      "y [0.89203581]\n",
      "0.11046632927814476\n",
      "y [0.89541648]\n",
      "0.10682102482391204\n",
      "y [0.8986865]\n",
      "0.10330730591653388\n",
      "y [0.90184979]\n",
      "0.09991968638612153\n",
      "y [0.90491009]\n",
      "0.09665295717631749\n",
      "y [0.90787102]\n",
      "0.09350216916096314\n",
      "y [0.91073604]\n",
      "0.09046261724131732\n",
      "y [0.91350848]\n",
      "0.08752982561258713\n",
      "y [0.91619155]\n",
      "0.08469953409952437\n",
      "y [0.91878831]\n",
      "0.0819676854706321\n",
      "y [0.92130173]\n",
      "0.07933041364923142\n",
      "y [0.92373466]\n",
      "0.07678403274741484\n",
      "y [0.92608984]\n",
      "0.07432502685586002\n",
      "y [0.9283699]\n",
      "0.07195004052868789\n",
      "y [0.93057739]\n",
      "0.06965586990813052\n",
      "y [0.93271474]\n",
      "0.06743945443875779\n",
      "y [0.93478432]\n",
      "0.06529786912551998\n",
      "y [0.93678838]\n",
      "0.063228317293898\n",
      "y [0.93872912]\n",
      "0.061228123814098416\n",
      "y [0.94060864]\n",
      "0.05929472875451678\n",
      "y [0.94242897]\n",
      "0.05742568143266521\n",
      "y [0.94419206]\n",
      "0.05561863483444087\n",
      "y [0.9458998]\n",
      "0.053871340375050356\n",
      "y [0.94755401]\n",
      "0.052181642977100186\n",
      "y [0.94915644]\n",
      "0.05054747644337625\n",
      "y [0.95070879]\n",
      "0.04896685910364273\n",
      "y [0.95221269]\n",
      "0.0474378897164489\n",
      "y [0.9536697]\n",
      "0.04595874360843793\n",
      "y [0.95508136]\n",
      "0.044527669035022054\n",
      "y [0.95644914]\n",
      "0.04314298374754072\n",
      "y [0.95777443]\n",
      "0.04180307175316099\n",
      "y [0.95905863]\n",
      "0.040506380254825475\n",
      "y [0.96030304]\n",
      "0.0392514167595051\n",
      "y [0.96150894]\n",
      "0.038036746343896366\n",
      "y [0.96267757]\n",
      "0.036860989067493945\n",
      "y [0.96381011]\n",
      "0.035722817523719454\n",
      "y [0.96490771]\n",
      "0.03462095452044684\n",
      "y [0.96597149]\n",
      "0.033554170881901935\n",
      "y [0.96700253]\n",
      "0.03252128336446831\n",
      "y [0.96800185]\n",
      "0.03152115267947306\n",
      "y [0.96897046]\n",
      "0.030552681616496078\n",
      "y [0.96990933]\n",
      "0.029614813261200412\n",
      "y [0.97081941]\n",
      "0.0287065293020931\n",
      "y [0.97170159]\n",
      "0.027826848420999768\n",
      "y [0.97255675]\n",
      "0.026974824762393237\n",
      "y [0.97338575]\n",
      "0.026149546477038096\n",
      "y [0.97418939]\n",
      "0.025350134335713613\n",
      "y [0.97496848]\n",
      "0.024575740409055177\n",
      "y [0.97572378]\n",
      "0.023825546809812276\n",
      "y [0.97645604]\n",
      "0.02309876449405842\n",
      "y [0.97716597]\n",
      "0.022394632118113267\n",
      "y [0.97785427]\n",
      "0.02171241494813535\n",
      "y [0.9785216]\n",
      "0.021051403819545587\n",
      "y [0.97916863]\n",
      "0.020410914143604696\n",
      "y [0.97979598]\n",
      "0.019790284958650615\n",
      "y [0.98040426]\n",
      "0.019188878023633945\n",
      "y [0.98099406]\n",
      "0.01860607695175393\n",
      "y [0.98156595]\n",
      "0.018041286382114118\n",
      "y [0.98212048]\n",
      "0.017493931187448266\n",
      "y [0.9826582]\n",
      "0.016963455716083205\n",
      "y [0.98317961]\n",
      "0.01644932306640939\n",
      "y [0.98368523]\n",
      "0.0159510143922346\n",
      "y [0.98417553]\n",
      "0.015468028237485654\n",
      "y [0.98465099]\n",
      "0.014999879898818052\n",
      "y [0.98511206]\n",
      "0.014546100814767945\n",
      "y [0.98555918]\n",
      "0.014106237980162148\n",
      "y [0.98599279]\n",
      "0.013679853384575169\n",
      "y [0.98641329]\n",
      "0.013266523473683267\n",
      "y [0.98682109]\n",
      "0.01286583863243887\n",
      "y [0.98721657]\n",
      "0.012477402689036488\n",
      "y [0.98760012]\n",
      "0.012100832438706204\n",
      "y [0.98797209]\n",
      "0.011735757186418805\n",
      "y [0.98833284]\n",
      "0.01138181830763429\n",
      "y [0.98868271]\n",
      "0.011038668826275277\n",
      "y [0.98902203]\n",
      "0.01070597300914605\n",
      "y [0.98935113]\n",
      "0.010383405976062405\n",
      "y [0.98967032]\n",
      "0.010070653324993885\n",
      "y [0.98997989]\n",
      "0.009767410771551957\n",
      "y [0.99028014]\n",
      "0.009473383802202242\n",
      "y [0.99057135]\n",
      "0.009188287340597399\n",
      "y [0.9908538]\n",
      "0.008911845426466926\n",
      "y [0.99112775]\n",
      "0.008643790906526543\n",
      "y [0.99139346]\n",
      "0.0083838651368927\n",
      "y [0.99165118]\n",
      "0.008131817696515723\n",
      "y [0.99190116]\n",
      "0.007887406111171872\n",
      "y [0.99214362]\n",
      "0.007650395587569475\n",
      "y [0.99237879]\n",
      "0.007420558757153883\n",
      "y [0.99260691]\n",
      "0.007197675429209121\n",
      "y [0.99282817]\n",
      "0.006981532352875656\n",
      "y [0.99304278]\n",
      "0.0067719229877273085\n",
      "y [0.99325095]\n",
      "0.006568647282552712\n",
      "y [0.99345288]\n",
      "0.006371511462020539\n",
      "y [0.99364874]\n"
     ]
    }
   ],
   "source": [
    "perceptron = Layer(5, Sigmoid(), 0.1, 100)\n",
    "\n",
    "a = perceptron.forward(np.array([1, 0.2, 0.3, 0.4, 0.5]))\n",
    "# print(a)\n",
    "perceptron.back(np.array([1]))\n",
    "# perceptron.back2(np.array([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2100ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecfecac",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 3 (2 балла)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcc0dc",
   "metadata": {},
   "source": [
    "напишите класс **LossFunction** и его подкласс **CrossEntropy**, у которого будет функция `loss`, которая будет принимать реальное бинарное значение *y_fact* и вероятность *y_prob* (оба параметра в виде np.array) и будет возвращать результат по формуле:  \n",
    "  \n",
    "$$\n",
    "L = - \\sum (y_{fact} * log(y_{prob}) + (1-y_{fact})*log(1-y_{prob}))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40a91107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "class LossFunction:\n",
    "    ...\n",
    "\n",
    "class CrossEntropy (LossFunction):\n",
    "\n",
    "    def loss(self, y_fact: np.ndarray, y_prob: np.ndarray):\n",
    "        res = 0\n",
    "        for i, j in zip(y_fact, y_prob):\n",
    "            res += i*log(j) + (1-i)*log(1-j)\n",
    "        return -res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a423f437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.83258146374831"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = CrossEntropy().loss(np.array([0]), np.array([0.84]))\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adeb1c5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><center><h1>Обучение. Forward and Backpropagation</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5305fa49",
   "metadata": {},
   "source": [
    "Процесс обучения персептрона (и в целом нейросети) итеративен и состоит из следующих этапов:\n",
    "- Сперва персептрон инициализируется с рандомальными весами\n",
    "- Осуществляется цикл \"вперёд\":\n",
    "  - Входные значения перемножаются с соответствующими весами и суммируются\n",
    "  - Эта сумма подаётся на функцию активации\n",
    "  - Функция активации возвращает итоговое значение\n",
    "- Итоговое значение сравнивается с ожидаемым и высчитывается ошибка (Loss)\n",
    "- Осуществляется цикл \"назад\":\n",
    "  - при помощи `Chain Rule` рассчитываются частичные производные для всех элементов персептрона\n",
    "  - исходя из заданного коэффициента обучения (`learning rate`, $\\alpha$), веса $w_{i}$ корректируются\n",
    "- Данный цикл повторяется заданное количество раз или до тех пор, пока итоговая ошибка не опустится ниже заданного порогового значения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f269a",
   "metadata": {},
   "source": [
    "![img](images/training.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561a0181",
   "metadata": {},
   "source": [
    "### <center>Chain Rule</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cc590",
   "metadata": {},
   "source": [
    "Если нам дана функция $y=f(u)$, где $u = g(x)$, то тогда производная этой функции по $x$ будет равно:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48de5834",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{dy}{dx} = \\frac{dy}{du}\\frac{du}{dx}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f31ddb",
   "metadata": {},
   "source": [
    "Тогда для того, чтобы понять, насколько изменение весов $w$ влияет на изменение $y$ (т.е. производные $\\frac{dy}{dw_{i}}$), можно вычислить следующие производные:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d239444",
   "metadata": {},
   "source": [
    "![neuron](images/backpropagation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6568f1db",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\"><center><h1>Задание 4 (8 баллов)</h1></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be53a81",
   "metadata": {},
   "source": [
    "Модифицируйте классы **Layer**, **LossFuncton** и **ActivationFunction** таким образом, чтобы можно было рассчитать их частичные производные, и добавьте функцию `back`, позволяющую осуществить backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9534b596",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><center><h3>Это задание очень сложное, и даже частичное его выполнение будет учитываться</h3></center></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a244e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f00233",
   "metadata": {},
   "source": [
    "# <center>Удачи!</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f685de6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
